{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Rhh0FTBU4G0Tt-yv-kNtLXivjMud8ii8","authorship_tag":"ABX9TyNFcRcMShVCSi9OxJ6tXTMS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8ce070d6"},"source":["# 1. Setup and Data Loading for Anomaly Detection"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Conv2D, MaxPooling2D, UpSampling2D\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.losses import MeanSquaredError\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","from google.colab import drive\n","\n","# Check TensorFlow and GPU\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n","\n","# --- Step 0: Mount ny any eGoogle Drive and Set Paths ---\n","print(\"\\nMounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"Google Drive mounted successfully!\")\n","\n","# Define the base directory for your dataset in Google Drive.\n","# IMPORTANT: CHANGE THIS PATH!\n","GOOGLE_DRIVE_DATASET_ROOT = '/content/drive/MyDrive/Dataset/chest_xray'\n","BASE_DIR = GOOGLE_DRIVE_DATASET_ROOT\n","\n","# Define directories for training, validation, and testing\n","train_dir = os.path.join(BASE_DIR, 'train')\n","val_dir = os.path.join(BASE_DIR, 'val')\n","test_dir = os.path.join(BASE_DIR, 'test')\n","\n","# Define directories to save models and visualizations\n","MODEL_SAVE_DIR = '/content/drive/MyDrive/pneumonia_project_models'\n","os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n","CLASSIFIER_PATH = '/content/drive/MyDrive/my_model_checkpoints/pneumonia_resnet_best_model.h5'\n","ANOMALY_DETECTOR_PATH = '/content/drive/MyDrive/pneumonia_project_models/anomaly_detector.h5'\n","\n","# Image parameters\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","BATCH_SIZE = 32\n","NUM_CLASSES = 2\n","\n","def create_autoencoder_generator(directory, image_size, batch_size):\n","    \"\"\"\n","    Creates a generator that yields (image, image) pairs for autoencoder training.\n","    \"\"\"\n","    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","        directory,\n","        target_size=image_size,\n","        batch_size=batch_size,\n","        class_mode=None,\n","        classes=['NORMAL'],\n","        shuffle=True\n","    )\n","    for batch in generator:\n","        yield (batch, batch)\n","\n","def get_anomaly_threshold(model, normal_train_dir, image_size, batch_size):\n","    \"\"\"\n","    Calculates the anomaly threshold based on the mean and standard deviation\n","    of reconstruction errors for a set of normal images.\n","    \"\"\"\n","    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","        os.path.dirname(normal_train_dir),\n","        target_size=image_size,\n","        batch_size=batch_size,\n","        classes=['NORMAL'],\n","        class_mode=None,\n","        shuffle=False\n","    )\n","\n","    num_samples = generator.samples\n","    errors = []\n","\n","    # Predict and calculate errors in batches\n","    for i in range(num_samples // batch_size):\n","        batch = next(generator)\n","        reconstructions = model.predict(batch)\n","        error = np.mean(np.square(reconstructions - batch), axis=(1, 2, 3))\n","        errors.extend(error)\n","\n","    return np.mean(errors) + 2 * np.std(errors)"],"metadata":{"id":"NLxmc0U0h_SK","executionInfo":{"status":"ok","timestamp":1754472738376,"user_tz":-330,"elapsed":1732,"user":{"displayName":"NexaThink","userId":"09927393797891117215"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb7076b5-920f-4fe3-ae58-18f48c49342f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 2.19.0\n","GPU Available: []\n","\n","Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Google Drive mounted successfully!\n"]}]},{"cell_type":"markdown","metadata":{"id":"08be928c"},"source":["# 2. Build, Train, and Threshold the Anomaly Detector"]},{"cell_type":"code","source":["ANOMALY_DETECTOR_PATH = '/content/drive/MyDrive/pneumonia_project_models/anomaly_detector.h5'\n","CLASSIFIER_PATH = '/content/drive/MyDrive/my_model_checkpoints/pneumonia_resnet_best_model.h5'\n","\n","# --- Step 4: Anomaly Detection with Autoencoder ---\n","print(\"\\n--- Building and Training Anomaly Detector (Autoencoder) ---\")\n","\n","BATCH_SIZE = 16\n","\n","# Remove the old model to ensure we train from scratch\n","if os.path.exists(ANOMALY_DETECTOR_PATH):\n","    print(\"Removing old anomaly detector model to train a new one...\")\n","    os.remove(ANOMALY_DETECTOR_PATH)\n","\n","# --- Corrected Generator for Autoencoder ---\n","def create_autoencoder_generator(directory, image_size, batch_size):\n","    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","        directory,\n","        target_size=image_size,\n","        batch_size=batch_size,\n","        class_mode=None, # Do not yield labels\n","        classes=['NORMAL'], # Only use normal images for training\n","        shuffle=True\n","    )\n","    for batch in generator:\n","        yield (batch, batch) # Yield the image as both input (x) and target (y)\n","\n","# We need a normal_train_generator to get the total number of samples\n","normal_train_dir = os.path.join(train_dir, 'NORMAL')\n","normal_train_generator_base = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","    os.path.dirname(normal_train_dir),\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    classes=['NORMAL'],\n","    class_mode=None,\n","    shuffle=False\n",")\n","\n","# Use the fixed generator that yields (x, x)\n","normal_train_generator_fixed = create_autoencoder_generator(\n","    os.path.dirname(normal_train_dir),\n","    (IMG_HEIGHT, IMG_WIDTH),\n","    BATCH_SIZE\n",")\n","\n","print(\"Building a new autoencoder model with improved architecture...\")\n","# Encoder\n","input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) # Deeper encoder\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","# Bottleneck with Dropout for better generalization\n","x = Dropout(0.2)(encoded)\n","\n","# Decoder\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","anomaly_detector = Model(input_img, decoded)\n","anomaly_detector.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse')\n","\n","print(\"Training the autoencoder on NORMAL images...\")\n","anomaly_detector.fit(\n","    normal_train_generator_fixed,\n","    steps_per_epoch=normal_train_generator_base.samples // BATCH_SIZE,\n","    epochs=20,\n","    callbacks=[\n","        ModelCheckpoint(\n","            filepath=ANOMALY_DETECTOR_PATH,\n","            save_best_only=True,\n","            monitor='loss'\n","        )\n","    ]\n",")\n","\n","print(\"\\nAutoencoder training complete. Model saved.\")\n","\n","print(\"\\nTo use the new model, continue running the next phase of the notebook.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"id":"hMnhjqHiiX82","executionInfo":{"status":"error","timestamp":1754520128842,"user_tz":-330,"elapsed":65703,"user":{"displayName":"NexaThink","userId":"09927393797891117215"}},"outputId":"423183b5-d7c4-4ce2-ddcd-9b0978c38cde","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found 1351 images belonging to 1 classes.\n","\n","--- Building and Training Anomaly Detector (Autoencoder) ---\n","Loading existing anomaly detector from /content/drive/MyDrive/pneumonia_project_models/anomaly_detector.h5...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Autoencoder training complete. Model saved.\n","\n","--- Setting Anomaly Detection Threshold ---\n","\n","Found 1351 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2375377358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# --- Step 3: Calculate Anomaly Detection Threshold ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Setting Anomaly Detection Threshold ---\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m anomaly_threshold = get_anomaly_threshold(\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0manomaly_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_train_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m )\n","\u001b[0;32m/tmp/ipython-input-3810540753.py\u001b[0m in \u001b[0;36mget_anomaly_threshold\u001b[0;34m(model, normal_train_dir, image_size, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Predict and calculate errors in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mreconstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         raise TypeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["ANOMALY_DETECTOR_PATH = '/content/drive/MyDrive/pneumonia_project_models/anomaly_detector.h5'\n","CLASSIFIER_PATH = '/content/drive/MyDrive/my_model_checkpoints/pneumonia_resnet_best_model.h5'\n","\n","final_classifier_model = tf.keras.models.load_model(CLASSIFIER_PATH)\n","\n","\n","# --- Step 6: Define Functions for Prediction, XAI (Grad-CAM), and Anomaly Detection ---\n","\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"conv5_block3_out\"):\n","    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","\n","def display_gradcam(image_path, model, last_conv_layer_name=\"conv5_block3_out\"):\n","    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array_preprocessed = np.expand_dims(img_array / 255.0, axis=0)\n","\n","    heatmap = make_gradcam_heatmap(img_array_preprocessed, model, last_conv_layer_name)\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(img, cmap='gray')\n","    plt.title(\"Original X-Ray\")\n","    plt.axis('off')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(img, cmap='gray')\n","    plt.imshow(heatmap, cmap='jet', alpha=0.5)\n","    plt.title(\"Grad-CAM Heatmap\")\n","    plt.axis('off')\n","    plt.show()\n","\n","def get_anomaly_threshold(model, normal_train_dir, image_size, batch_size):\n","    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n","        os.path.dirname(normal_train_dir),\n","        target_size=image_size,\n","        batch_size=batch_size,\n","        classes=['NORMAL'],\n","        class_mode=None,\n","        shuffle=False\n","    )\n","\n","    num_samples = generator.samples\n","    errors = []\n","\n","    for i in range(num_samples // batch_size):\n","        batch = next(generator)\n","        reconstructions = model.predict(batch)\n","        error = np.mean(np.square(reconstructions - batch), axis=(1, 2, 3))\n","        errors.extend(error)\n","\n","    return np.mean(errors) + 2 * np.std(errors)\n","\n","\n","# --- NEW FUNCTION: Get Anomaly Coordinates ---\n","def get_anomaly_coordinates(original_img_array_preprocessed, reconstruction_img_array, error_threshold_for_pixels=0.01):\n","    \"\"\"\n","    Calculates pixel-wise reconstruction error and returns bounding box coordinates\n","    of anomalous regions.\n","\n","    Args:\n","        original_img_array_preprocessed (np.array): Original image (preprocessed, e.g., scaled to [0,1]).\n","                                                    Shape (1, H, W, C).\n","        reconstruction_img_array (np.array): Reconstructed image from autoencoder.\n","                                             Shape (1, H, W, C).\n","        error_threshold_for_pixels (float): Pixel-wise error threshold to consider a pixel anomalous.\n","                                            Adjust this value based on visual inspection.\n","                                            A higher value means stricter anomaly detection.\n","                                            (e.g., 0.01 means 1% difference is anomalous)\n","\n","    Returns:\n","        list of tuples: Each tuple represents a bounding box (x_min, y_min, x_max, y_max)\n","                        If no anomalies, returns an empty list.\n","    \"\"\"\n","    # Calculate pixel-wise squared error\n","    pixel_error = np.mean(np.square(original_img_array_preprocessed - reconstruction_img_array), axis=-1)\n","    pixel_error = pixel_error[0] # Remove batch dimension\n","\n","    # Threshold the pixel error to create a binary mask of anomalous regions\n","    anomaly_mask = pixel_error > error_threshold_for_pixels\n","\n","    # Find contours or connected components to get bounding boxes\n","    # Using a simple bounding box around all anomalous pixels for now\n","    # For more complex shapes, you'd use OpenCV's findContours\n","\n","    anomalous_pixels = np.argwhere(anomaly_mask)\n","\n","    if len(anomalous_pixels) == 0:\n","        return [] # No anomalous pixels found\n","\n","    # Get min/max coordinates\n","    y_min, x_min = anomalous_pixels.min(axis=0)\n","    y_max, x_max = anomalous_pixels.max(axis=0)\n","\n","    # Return as (x_min, y_min, x_max, y_max)\n","    return [(x_min, y_min, x_max, y_max)]\n","\n","\n","def comprehensive_prediction(image_path, classifier_model, anomaly_detector, anomaly_threshold):\n","    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array_preprocessed = np.expand_dims(img_array / 255.0, axis=0)\n","\n","    # 1. Pneumonia Prediction\n","    pneumonia_prediction = classifier_model.predict(img_array_preprocessed)[0][0]\n","    is_pneumonia = \"Pneumonia\" if pneumonia_prediction > 0.5 else \"Normal\"\n","\n","    # 2. Anomaly Detection (Image-level)\n","    reconstruction = anomaly_detector.predict(img_array_preprocessed)\n","    reconstruction_error = np.mean(np.square(reconstruction - img_array_preprocessed))\n","    is_anomaly = reconstruction_error > anomaly_threshold\n","\n","    print(f\"\\n--- Analysis for Image: {os.path.basename(image_path)} ---\")\n","    print(f\"Pneumonia Prediction: {is_pneumonia} (Confidence: {pneumonia_prediction:.2f})\")\n","    print(f\"Anomaly Detected: {'Yes' if is_anomaly else 'No'} (Reconstruction Error: {reconstruction_error:.4f})\")\n","\n","    # 3. Anomaly Localization (Pixel-level)\n","    anomaly_coords = []\n","    if is_anomaly: # Only get coordinates if image is flagged as anomalous\n","        # You might need to tune this pixel_error_threshold based on your data\n","        anomaly_coords = get_anomaly_coordinates(img_array_preprocessed, reconstruction, error_threshold_for_pixels=0.01)\n","        if anomaly_coords:\n","            print(f\"Anomaly Coordinates (x_min, y_min, x_max, y_max): {anomaly_coords}\")\n","        else:\n","            print(\"No significant anomalous regions found at the pixel level based on threshold.\")\n","\n","    # 4. Explainable AI (Grad-CAM)\n","    display_gradcam(image_path, classifier_model)\n","\n","    return is_pneumonia, is_anomaly, anomaly_coords\n","\n","# --- Example of Comprehensive Prediction on a New Image ---\n","if os.path.exists(ANOMALY_DETECTOR_PATH) and final_classifier_model is not None:\n","    anomaly_detector = tf.keras.models.load_model(\n","        ANOMALY_DETECTOR_PATH,\n","        custom_objects={'mse': tf.keras.losses.MeanSquaredError()}\n","    )\n","\n","    normal_train_dir_for_threshold = os.path.join(train_dir, 'NORMAL')\n","    anomaly_threshold = get_anomaly_threshold(\n","        anomaly_detector,\n","        normal_train_dir_for_threshold,\n","        (IMG_HEIGHT, IMG_WIDTH),\n","        BATCH_SIZE\n","    )\n","    print(f\"\\nAnomaly Detection Threshold (Image-level): {anomaly_threshold:.4f}\")\n","\n","    # Example prediction on a test pneumonia image\n","    test_pneumonia_path = os.path.join(test_dir, 'PNEUMONIA', os.listdir(os.path.join(test_dir, 'PNEUMONIA'))[51])\n","    comprehensive_prediction(test_pneumonia_path, final_classifier_model, anomaly_detector, anomaly_threshold)\n","\n","    # Example prediction on a test normal image\n","    test_normal_path = os.path.join(test_dir, 'NORMAL', os.listdir(os.path.join(test_dir, 'NORMAL'))[51])\n","    comprehensive_prediction(test_normal_path, final_classifier_model, anomaly_detector, anomaly_threshold)\n","else:\n","    print(\"\\nError: Anomaly detector model or classifier model not found. Please run the training phases first.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4eePkomqZww","outputId":"3336b7e3-5d5e-4b57-d008-3a08d4b2f5b1"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Found 1351 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"]}]}]}